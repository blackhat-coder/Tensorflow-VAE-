{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.84765531e+10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([20000.0999833434]) * np.array([923823.034930])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.function_base import gradient\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_test(keras.Model):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder_test, self).__init__(**kwargs)\n",
    "\n",
    "        # self.input_layer = keras.layers.Input(shape=(INPUT_SIZE))\n",
    "\n",
    "        # self.f = keras.layers.Flatten()\n",
    "        # self.l1 = keras.layers.Dense(364, activation=\"relu\")\n",
    "        # self.l2 = keras.layers.Dense(224, activation=\"relu\")\n",
    "        # self.l3 = keras.layers.Dense(124, activation=\"relu\")\n",
    "        # self.l4 = keras.layers.Dense(64, activation=\"relu\")\n",
    "        # self.l5 = keras.layers.Dense(24)\n",
    "                \n",
    "        self.conv_layer_one = keras.layers.Conv2D(24, 3, padding=\"valid\", activation=\"relu\") # 26 x 26\n",
    "        self.conv_layer_two = keras.layers.Conv2D(64, 3, padding=\"valid\", activation=\"relu\") # 24 X 24\n",
    "        self.pool_one = keras.layers.MaxPool2D(2, 2) # 12 x 12 X 64\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "\n",
    "        # inputs = self.input_layer(inputs)\n",
    "        # inputs = self.f(inputs)\n",
    "        # inputs = self.l1(inputs)\n",
    "        # inputs = self.l2(inputs)\n",
    "        # inputs = self.l3(inputs)\n",
    "        # inputs = self.l4(inputs)\n",
    "        # inputs = self.l5(inputs)\n",
    "\n",
    "\n",
    "        inputs = self.conv_layer_one(inputs)\n",
    "        inputs = self.conv_layer_two(inputs)\n",
    "        inputs = self.pool_one(inputs)\n",
    "\n",
    "        flatten = keras.layers.Flatten()(inputs)\n",
    "        fcn = keras.layers.Dense(64, activation=\"relu\")(flatten)\n",
    "\n",
    "        mean = keras.layers.Dense(LATENT_DIM)(fcn)\n",
    "        mu_ = keras.layers.Dense(LATENT_DIM)(fcn)\n",
    "\n",
    "        # mean = keras.layers.Dense(LATENT_DIM)(inputs)\n",
    "        # mu_ = keras.layers.Dense(LATENT_DIM)(inputs)\n",
    "\n",
    "        # enc_model = keras.models.Model( \n",
    "        #     inputs=[inputs], \n",
    "        #     outputs=[mean, mu_]\n",
    "        # )\n",
    "        \n",
    "        return (mean, mu_)\n",
    "\n",
    "class Decoder_test(keras.Model):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder_test, self).__init__(**kwargs)\n",
    "\n",
    "        self.input_layer = keras.layers.Input(shape=(LATENT_DIM) )\n",
    "        # self.dense_layer = keras.layers.Dense(7 * 7 * 128)\n",
    "        # self.reshape_layer = keras.layers.Reshape((7, 7, 128))\n",
    "\n",
    "        # self.l_1 = keras.layers.Dense(24, activation=\"relu\")\n",
    "        # self.l_2 = keras.layers.Dense(64, activation=\"relu\")\n",
    "        # self.l_3 = keras.layers.Dense(124, activation=\"relu\")\n",
    "        # self.l_4 = keras.layers.Dense(224, activation=\"relu\")\n",
    "        # self.l_5 = keras.layers.Dense(364, activation=\"relu\")\n",
    "        # self.l_6 = keras.layers.Dense(28*28, activation=\"sigmoid\")\n",
    "\n",
    "        self.l_1_c = keras.layers.Dense(12*12, activation=\"relu\")\n",
    "        self.l_2_c = keras.layers.Reshape((12, 12, 1))\n",
    "        self.l_3_c = keras.layers.Conv2DTranspose(64, 3, padding=\"valid\", activation=\"relu\")\n",
    "        self.l_4_c = keras.layers.Conv2DTranspose(24, 3, strides=2,padding=\"same\", activation=\"relu\")\n",
    "        self.l_5_c = keras.layers.Conv2DTranspose(1, 3, padding=\"same\", activation=\"sigmoid\")\n",
    "        self.r = keras.layers.Reshape((28, 28))\n",
    "\n",
    "        # write the sequential model in __call__()\n",
    "    def __call__(self, inputs):\n",
    "        \n",
    "        dec_model = keras.models.Sequential([\n",
    "            self.input_layer,\n",
    "            # self.l_1,\n",
    "            self.l_1_c,\n",
    "            self.l_2_c,\n",
    "            self.l_3_c,\n",
    "            self.l_4_c,\n",
    "            self.l_5_c,\n",
    "            self.r\n",
    "        ])\n",
    "\n",
    "        return dec_model(inputs)\n",
    "\n",
    "\n",
    "class Sampling(keras.layers.Layer):\n",
    "    \n",
    "    '''\n",
    "    Reparamaterization Trick\n",
    "    '''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Sampling, self).__init__(**kwargs)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "\n",
    "        '''\n",
    "        Args:\n",
    "            inputs - A tuple containing (mean, variance)\n",
    "            output - A vector of shape LATENT_DIM\n",
    "        '''\n",
    "\n",
    "        mean, log_var = inputs\n",
    "        sample = tf.random.normal([LATENT_DIM]) * tf.exp(log_var / 2) + mean\n",
    "\n",
    "        return sample\n",
    "\n",
    "class VAE_test(keras.Model):\n",
    "    # Implement Holding the latent Vector\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(VAE_test, self).__init__(**kwargs)\n",
    "\n",
    "        self.encoder = Encoder_test()\n",
    "        self.decoder = Decoder_test()\n",
    "    \n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        '''\n",
    "        Args:\n",
    "            -input : inputs , shape = (batch, INPUT_SIZE , INPUT_SIZE)\n",
    "\n",
    "            -output : (reconstruction, mean, log_var)\n",
    "                reconstruction : shape = (batch, INPUT_SIZE, INPUT_SIZE)\n",
    "                mean           : shape = (LATENT_DIM, 1)\n",
    "                log_var        : shape = (LATENT_DIM, 1)\n",
    "    \n",
    "        '''\n",
    "\n",
    "        inputs = inputs\n",
    "\n",
    "        mean, log_var = self.encoder(inputs) #shape : INPUT_SIZE\n",
    "\n",
    "        latent_vector = Sampling()((mean, log_var))\n",
    "\n",
    "        reconstruction = self.decoder(latent_vector)\n",
    "\n",
    "        # vae_model = keras.models.Model(inputs=[inputs], outputs=[reconstruction])\n",
    "\n",
    "        return reconstruction, mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch == 20:\n",
    "        lr = epoch / 10\n",
    "    if epoch == 30:\n",
    "        lr = epoch / 10\n",
    "    \n",
    "    return lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting tarining.py\n",
      "WARNING:tensorflow:Layer conv2d_160 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch: 0\n",
      "loss: 1024.51318359375\n",
      "Epoch: 1\n",
      "loss: 779.0664672851562\n",
      "Epoch: 2\n",
      "loss: 704.45458984375\n",
      "Epoch: 3\n",
      "loss: 1065.6417236328125\n",
      "Epoch: 4\n",
      "loss: 793.8373413085938\n",
      "Epoch: 5\n",
      "loss: 798.5675048828125\n",
      "Epoch: 6\n",
      "loss: 936.0548095703125\n",
      "Epoch: 7\n",
      "loss: 799.700439453125\n",
      "Epoch: 8\n",
      "loss: 801.697509765625\n",
      "Epoch: 9\n",
      "loss: 915.9576416015625\n",
      "Epoch: 10\n",
      "loss: 816.7108154296875\n",
      "Epoch: 11\n",
      "loss: 754.973876953125\n",
      "Epoch: 12\n",
      "loss: 944.64111328125\n",
      "Epoch: 13\n",
      "loss: 795.0830078125\n",
      "Epoch: 14\n",
      "loss: 799.7366943359375\n",
      "Epoch: 15\n",
      "loss: 912.8334350585938\n",
      "Epoch: 16\n",
      "loss: 765.377685546875\n",
      "Epoch: 17\n",
      "loss: 734.0202026367188\n",
      "Epoch: 18\n",
      "loss: 952.5753173828125\n",
      "Epoch: 19\n",
      "loss: 765.973388671875\n",
      "Epoch: 20\n",
      "loss: 745.3285522460938\n",
      "Epoch: 21\n",
      "loss: 831.0460205078125\n",
      "Epoch: 22\n",
      "loss: 915.8441162109375\n",
      "Epoch: 23\n",
      "loss: 740.5551147460938\n",
      "Epoch: 24\n",
      "loss: 823.9666137695312\n",
      "Epoch: 25\n",
      "loss: 849.8096313476562\n",
      "Epoch: 26\n",
      "loss: 696.8753662109375\n",
      "Epoch: 27\n",
      "loss: 803.6757202148438\n",
      "Epoch: 28\n",
      "loss: 720.1309814453125\n",
      "Epoch: 29\n",
      "loss: 656.6329956054688\n",
      "Epoch: 30\n",
      "loss: 749.6380615234375\n",
      "Epoch: 31\n",
      "loss: 754.7616577148438\n",
      "Epoch: 32\n",
      "loss: 726.078857421875\n",
      "Epoch: 33\n",
      "loss: 902.1321411132812\n",
      "Epoch: 34\n",
      "loss: 867.7349853515625\n",
      "Epoch: 35\n",
      "loss: 896.8949584960938\n",
      "Epoch: 36\n",
      "loss: 686.4717407226562\n",
      "Epoch: 37\n",
      "loss: 864.508544921875\n",
      "Epoch: 38\n",
      "loss: 752.8486328125\n",
      "Epoch: 39\n",
      "loss: 799.8438110351562\n",
      "Epoch: 40\n",
      "loss: 743.3294067382812\n",
      "Epoch: 41\n",
      "loss: 794.3260498046875\n",
      "Epoch: 42\n",
      "loss: 752.3856811523438\n",
      "Epoch: 43\n",
      "loss: 1043.918701171875\n",
      "Epoch: 44\n",
      "loss: 806.072998046875\n",
      "Epoch: 45\n",
      "loss: 887.9518432617188\n",
      "Epoch: 46\n",
      "loss: 772.5164794921875\n",
      "Epoch: 47\n",
      "loss: 823.0066528320312\n",
      "Epoch: 48\n",
      "loss: 936.88671875\n",
      "Epoch: 49\n",
      "loss: 724.9259033203125\n",
      "session ended\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from numpy.lib.function_base import gradient\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "from utils import LATENT_DIM\n",
    "from utils import NO_EPOCHS\n",
    "from utils import BATCH_SIZE\n",
    "from utils import LEARNING_RATE\n",
    "\n",
    "from models.model_def import VAE\n",
    "from models.model_def import Encoder\n",
    "from models.model_def import Decoder\n",
    "\n",
    "keras_loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "\n",
    "# Refactor Network_loss into class Network_loss\n",
    "def Network_loss(mean, log_var, alpha=1, beta=1):\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = tf.reshape(y_true, (-1, 28, 28))\n",
    "        y_pred = tf.reshape(y_pred, (-1, 28, 28))\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        # assert y_true.dtype = tf.float32, \"use tf.cast() to cast y_true to type tf.float32\"\n",
    "\n",
    "        latent_loss = 1 + log_var - tf.square(mean) - tf.exp(log_var)\n",
    "        latent_loss = -0.5 + tf.reduce_sum(latent_loss, 1)\n",
    "\n",
    "        recons_loss = y_true * tf.math.log(1e-10+y_pred) + (1 - y_true) * tf.math.log(1e-10 + 1 - y_pred)\n",
    "        recons_loss = -tf.reduce_sum(recons_loss)\n",
    "\n",
    "        network_loss = alpha * recons_loss + beta * latent_loss\n",
    "        network_loss = tf.reduce_mean(network_loss)\n",
    "\n",
    "        return network_loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
    "\n",
    "x_train = x_train/255.0\n",
    "\n",
    "\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "x_train = x_train[4:200]\n",
    "y_train = y_train[4:200]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(12)\n",
    "\n",
    "\n",
    "p_t = []\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.003)\n",
    "\n",
    "log_grads = []\n",
    "\n",
    "def train():\n",
    "\n",
    "    model = VAE()\n",
    "\n",
    "    for epoch in range(50):\n",
    "\n",
    "        for step, (batch_x, batch_y) in enumerate(train_dataset):\n",
    "            # print(batch_x.shape)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "\n",
    "                (predictions, mean, lg_var) = model(batch_x)\n",
    "\n",
    "                loss = Network_loss(mean, lg_var, alpha=1, beta=1)\n",
    "                loss_ = loss(batch_x, predictions)\n",
    "\n",
    "                # batch_x = np.reshape(batch_x, (1,784))\n",
    "                # loss_ = keras_loss(batch_x, predictions)\n",
    "            \n",
    "            gradients = tape.gradient(loss_, model.trainable_weights)\n",
    "            \n",
    "            clipped_grads = [tf.clip_by_value(grad, -1., 1.)  for grad in gradients]\n",
    "\n",
    "            \n",
    "\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "        # lr_scheduler(epoch, \"SGD\")\n",
    "\n",
    "        log_grads.append({ f\"epoch:{epoch}\":[ {\"max\":max} , {\"min\": min}, {\"mean\":mean}   ] })\n",
    "\n",
    "        if epoch > 30:\n",
    "            optimizer._initial_decay = 2.0\n",
    "            \n",
    "        print(f\"Epoch: {epoch}\\nloss: {loss_}\")\n",
    "        p_t.append(predictions)\n",
    "        # Write Checkpoint at epoch level or at batch level\n",
    "\n",
    "\n",
    "def test_loss():\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.pyplot as plt\n",
    "    import cv2\n",
    "    x_t = x_train[4:5]\n",
    "\n",
    "    t_model = VAE()\n",
    "    t_y, m, v = t_model(x_t)\n",
    "\n",
    "    print(\"pred shape\")\n",
    "    print(t_y.shape)\n",
    "    print(\"input shape\")\n",
    "    print(x_t.shape)\n",
    "\n",
    "    t_y = np.reshape(t_y, [28, 28])\n",
    "    x_t = np.reshape(x_t, [28, 28])\n",
    "    \n",
    "    cv2.imwrite(\"x_t.jpg\", x_t)\n",
    "    # cv2.imwrite(\"t_y.jpg\", t_y)\n",
    "    \n",
    "    print(f\"loss:{ Network_loss(m, v)(x_t, t_y) } \")\n",
    "\n",
    "    # print(np.array(x_t))\n",
    "    plt.imshow(x_t)\n",
    "    # plt.imshow(t_y)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting tarining.py\")\n",
    "    train()\n",
    "    # test_loss()\n",
    "    print(\"session ended\")\n",
    "    # print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!. I'm Excited!!! We have a lead, with optimizer Adam, loss:174, lr:0.001\n",
    "\n",
    "batch size- 5, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 28, 28])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_t[40].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e1dcb21880>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.imshow(np.reshape(p_t[29][0], [28, 28])) \n",
    "plt.imshow(np.reshape(p_t[30][0], [28, 28]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!. I'm Excited!!! We have a lead, with optimizer Adam, loss:174, lr:0.001.\n",
    "\n",
    "with Adam VAE(), latent_dim = 4, loss = 120(36 epoch), lr=0.003, batch_size=5, trian_len=46, epochs=50, we can see something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x1e0a62d9a00>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer._initial_decay = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dde510855eb91e91d87b0b17f77277c0b378a00f0b3059b636abe476ec7ee314"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('condaenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
